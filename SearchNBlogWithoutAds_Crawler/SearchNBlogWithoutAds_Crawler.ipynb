{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from pprint import pprint\n",
    "import requests\n",
    "import urllib.request\n",
    "import os\n",
    "import urllib.parse\n",
    "import shutil\n",
    "from io import BytesIO\n",
    "\n",
    "#import cv2\n",
    "from PIL import Image\n",
    "import time\n",
    "import tensorflow.keras\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fakeBlogKeywordList = [\"스토리앤\",\"seoulouba\",\"mateb.kr\",\"revu\",\"weble\",\"ohmyblog\",\"mrblog\",\"tble\",\n",
    "    \"dinnerqueen\",\"%EA%B3%B5%EC%A0%95%EA%B1%B0%EB%9E%98%EC%9C%84%EC%9B%90%ED%9A%8C-%EB%AC%B8%EA%B5%AC\",\n",
    "    \"%EB%B8%94%EB%A1%9C%EA%B7%B8%EC%9B%90%EC%A0%95%EB%8C%80\",\n",
    "    \"banner_\",\"%EC%9D%B4%EC%8A%88%EB%B8%94%EB%A1%9C%EA%B7%B8\",\n",
    "    \"%EB%B0%B0%EB%84%88\",\"http://echoblog.net/images/sponsor-banner.png\",\n",
    "                      \"sponsor\",\"banner\",\"echoblog\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#define const value\n",
    "batch_size = 3000\n",
    "epochs = 15\n",
    "IMG_HEIGHT = 260\n",
    "IMG_WIDTH = 460\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
    "        MaxPooling2D(),\n",
    "        Conv2D(32, 3, padding='same', activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_diff_width_0624_v1(batch-3000)/cp-0015.ckpt\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "#load model\n",
    "checkpoint_path = \"model_diff_width_0624_v1(batch-3000)/cp-0015.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "print(latest)\n",
    "\n",
    "# create model\n",
    "model = create_model()\n",
    "model.load_weights(latest)\n",
    "\n",
    "data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
    "teachable_model = tensorflow.keras.models.load_model('/Users/esens/Downloads/converted_keras/keras_model.h5')\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PredictionWithoutDownload(uri):\n",
    "    start_time = time.time();\n",
    "    \n",
    "#     response = requests.get(uri)\n",
    "    response = urllib.request.urlopen(uri).read()\n",
    "#     print(\"---[1] {}s seconds---\".format(time.time()-start_time,\".2f\"))\n",
    "    start_time = time.time();\n",
    "    #image = tf.keras.preprocessing.image.load_img(image_path,target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
    "#     img = Image.open(BytesIO(response.content))\n",
    "    img = Image.open(BytesIO(response))\n",
    "#     print(\"---[2] {}s seconds---\".format(time.time()-start_time,\".2f\"))\n",
    "    start_time = time.time();\n",
    "    #width,height\n",
    "    resize_img = img.resize((IMG_WIDTH, IMG_HEIGHT))\n",
    "#     print(\"---[3] {}s seconds---\".format(time.time()-start_time,\".2f\"))\n",
    "    start_time = time.time();\n",
    "\n",
    "    input_arr = tf.keras.preprocessing.image.img_to_array(resize_img)\n",
    "    input_arr = np.array([input_arr])  # Convert single image to a batch.\n",
    "#     print(\"---[4] {}s seconds---\".format(time.time()-start_time,\".2f\"))\n",
    "    start_time = time.time();\n",
    "    \n",
    "    predictions_class = model.predict_classes(input_arr)\n",
    "#     print(\"---[5] {}s seconds---\".format((time.time()-start_time),\".2f\"))\n",
    "\n",
    "#     predictions = model.predict(input_arr)\n",
    "    print(\"========pridiction[Without Download]========\");\n",
    "#     print(test_data_gen.class_indices)\n",
    "    print(\"predictions class : \" , predictions_class);\n",
    "#     print(\"predictions : \" , predictions)\n",
    "    return predictions_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =====================================================================\n",
    "#이미지 분류 [teachable machine model]\n",
    "def teachableMachinePrediction(image_path):\n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "        size = (224, 224)\n",
    "        image = ImageOps.fit(image, size, Image.ANTIALIAS)\n",
    "        resize = Image.open(image_path);\n",
    "        print(\"image size : \",resize.size);\n",
    "        \n",
    "        image_array = np.asarray(image)\n",
    "        normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1\n",
    "        newdata = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)    \n",
    "        \n",
    "#         data = np.array([np.array(cv2.imread(image_path[i])) for i in range(len(image_path))])\n",
    "#         features = data.flatten().reshape(1, 224,224,3)\n",
    "#         print(\"features : \" , features.shape)\n",
    "\n",
    "        if(normalized_image_array.shape == (224,224,4)):\n",
    "            print('224,224,4 : ' , image_path)\n",
    "            print(normalized_image_array.shape)\n",
    "            normalized_image_array_reshape = normalized_image_array.reshape(224,224,3)\n",
    "            print(normalized_image_array_reshape.shape)\n",
    "\n",
    "        elif (normalized_image_array.shape == (224, 224)):\n",
    "            print('224,224 : ', image_path)\n",
    "            normalized_image_array_reshape = normalized_image_array.reshape(-1,224,224,3)\n",
    "            print(normalized_image_array_reshape.shape)\n",
    "\n",
    "        else:\n",
    "            normalized_image_array_reshape = normalized_image_array.reshape(1,224,224,3)\n",
    "\n",
    "        # Load the image into the array\n",
    "        newdata[0] = normalized_image_array_reshape\n",
    "        #todo image shape 다른경우 처리해줘야함(png일 때 로 추측됨..)\n",
    "        print('newdata.shape : ' , newdata.shape)\n",
    "  \n",
    "        #predictions class \n",
    "        # {0 : advertise , 1: others}\n",
    "        \n",
    "        prediction = teachable_model.predict(newdata)\n",
    "        prediction_class = teachable_model.predict_classes(newdata)\n",
    "        #print(\"========pridiction[teachable]========\")\n",
    "        #print(prediction_class)\n",
    "    except Exception as ex:\n",
    "        print(\"predict error[teachable machine] : \" , ex)\n",
    "        \n",
    "    return prediction_class\n",
    "\n",
    "    \n",
    "# =====================================================================\n",
    "#이미지 분류 [my model]\n",
    "\n",
    "def imageClassification(image_path):\n",
    "    image = tf.keras.preprocessing.image.load_img(image_path,target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
    "    input_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
    "#    print(\"input_arr type : \" ,type(input_arr))\n",
    "    input_arr = np.array([input_arr])  # Convert single image to a batch.\n",
    "\n",
    "    predictions_class = model.predict_classes(input_arr)\n",
    "    predictions = model.predict(input_arr)\n",
    "\n",
    "    print(\"========pridiction========\");\n",
    "#     print(test_data_gen.class_indices)\n",
    "    print(\"predictions class : \" , predictions_class);\n",
    "    print(\"predictions : \" , predictions);\n",
    "#    print(\"predictions argmax : \",np.argmax(predictions[0])); # same way\n",
    "    return predictions_class;\n",
    "\n",
    "# =====================================================================\n",
    "#이미지 저장\n",
    "def saveImage(div_option,index,img_url,nickName,postNumber):\n",
    "    #블로그 유저 별로 폴더를 나눌건지에 대한 옵션\n",
    "    #true -> path : image/{nickName}/{postNumber}\n",
    "    #false -> path : image/myimg/\n",
    "    if(div_option):\n",
    "        if nickName is \"\":\n",
    "            nickName = \"unknown\"\n",
    "        if postNumber is \"\":\n",
    "            postNumber = \"1\"        \n",
    "        imgPath = f'image/{nickName}/{postNumber}/{index}.jpg'\n",
    "        dirPath = f'image/{nickName}/{postNumber}'\n",
    "    #폴더별로 분기하지 않을떄 path : image/myimg/\n",
    "    else:\n",
    "        list = os.listdir(\"image/temp\")\n",
    "        last_index = len(list)\n",
    "#         print(\"last_index : \",last_index)\n",
    "        dirPath = 'image/temp'\n",
    "        imgPath = f'image/temp/{last_index}.jpg'\n",
    "    \n",
    "    if not os.path.isdir(dirPath):\n",
    "        #폴더 생성\n",
    "        try:\n",
    "            os.makedirs(dirPath)\n",
    "        except Exception as ex:\n",
    "            print(\"error catch : \" , ex)\n",
    "                \n",
    "    #파일 저장\n",
    "    #temp에 저장 -> classification -> 분류 저장\n",
    "    \n",
    "    try:\n",
    "        filename = img_url.split('/')[-1].split('?')[0];\n",
    "        img_url2 = urllib.parse.quote_plus(str(filename))\n",
    "        img_url_final = img_url.replace(img_url.split('/')[-1].split('?')[0],img_url2)\n",
    "#         print(\"img_url_final : \" ,img_url_final);\n",
    "        for item in fakeBlogKeywordList:\n",
    "            if(img_url_final.find(item) > 0):\n",
    "                print('this is fake img')\n",
    "\n",
    "                imgPath = f\"image/temp/fake_{last_index}.jpg\"\n",
    "                break;\n",
    "        \n",
    "        urllib.request.urlretrieve(img_url_final, imgPath)\n",
    "        #분류\n",
    "        #{'advertise': 0, 'image': 1}\n",
    "        my_prediction  = imageClassification(imgPath);\n",
    "        #my_prediction  = teachableMachinePrediction(imgPath);\n",
    "#         print(\"prediction : \", my_prediction[0]);\n",
    "        \n",
    "        if (my_prediction[0] == 0):\n",
    "            list = os.listdir(\"ad_img\")\n",
    "            last_index = len(list)\n",
    "            #os.rename(imgPath, f'ad_img/{last_index}.jpg')\n",
    "            #shutil.move(imgPath, f'ad_img/{last_index}.jpg')\n",
    "            os.replace(imgPath, f'ad_img/{last_index}.jpg')\n",
    "            return False\n",
    "        return True\n",
    "    except Exception as ex:\n",
    "        print(\"img save error : \" , ex)\n",
    "        return False\n",
    "    \n",
    "    \n",
    "# =====================================================================\n",
    "# image gethering\n",
    "def findBlogImgGethering(searchQuery, searchOption, page):\n",
    "    try:\n",
    "        start_time = time.time();\n",
    "\n",
    "        url = f'https://search.naver.com/search.naver?query={searchQuery}&sm=tab_pge&srchby=all&st={searchOption}&where=post&start={page}'\n",
    "        html = requests.get(url)\n",
    "        # 1차, blog URL 찾기\n",
    "        soup = BeautifulSoup(html.text, 'html.parser')\n",
    "        index = 0;\n",
    "\n",
    "        url_list = [];\n",
    "        for li_item in soup.find_all('li',{'class' : 'sh_blog_top'}):\n",
    "            child_item = li_item.find('a',{'class' : 'sh_blog_title'})\n",
    "            title = child_item.attrs['title']\n",
    "            href = child_item.attrs['href']\n",
    "\n",
    "            #url list 저장\n",
    "            url_list.append(href)\n",
    "\n",
    "            print(f'title : {title} , href : {href}')\n",
    "            print('----------------------------------')\n",
    "\n",
    "        # url 파싱 및 예외처리\n",
    "        for url_item in url_list:\n",
    "            nickName = \"\";\n",
    "            postNumber = \"\";\n",
    "\n",
    "            if(url_item.find(\"blog.me\") > 0):\n",
    "                parsing = url_item;\n",
    "                parsing = parsing.replace(\"https://\",\"\")\n",
    "                nickName = parsing.split('.')[0]\n",
    "                postNumber = parsing.split('/')[1]\n",
    "                blogUrl = \"https://m.blog.naver.com/\" + nickName + \"?Redirect=Log&logNo=\" + postNumber\n",
    "\n",
    "            else:\n",
    "                blogUrl = url_item.replace(\"https://\", \"https://m.\");\n",
    "\n",
    "            nickName = blogUrl.split('/')[-1].split('?')[0]\n",
    "            postNumber = blogUrl.split('/')[-1].split('?')[1].split('=')[-1]\n",
    "\n",
    "            if nickName is \"\":\n",
    "                nickName = \"unknown\"\n",
    "            if postNumber is \"\":\n",
    "                postNumber = \"1\"\n",
    "\n",
    "            print(\"------ digging more -------\")\n",
    "            print(\"nickName : \" , blogUrl.split('/')[-1].split('?')[0])\n",
    "            print(\"postNumber : \" , blogUrl.split('/')[-1].split('?')[1].split('=')[-1])\n",
    "            print(\"blogUrl : \" , blogUrl)        \n",
    "            start_time = time.time();\n",
    "            #전체 목록 순회\n",
    "            blog_html = requests.get(blogUrl)\n",
    "            blog_soup = BeautifulSoup(blog_html.text, 'html.parser')\n",
    "            blog_image_class = blog_soup.find_all('div',{'class' : 'se-image'});\n",
    "\n",
    "            for div_obj in blog_image_class:\n",
    "                for idx, img_item in enumerate(div_obj.find_all('img')):\n",
    "                    img_url = img_item.attrs['src'];\n",
    "\n",
    "                    if(img_url.find(\"w80_blur\") > 0):\n",
    "                        img_url = img_url.replace(\"w80_blur\" , \"w800\")\n",
    "                        #np array after save image(for crawling data)\n",
    "                    #isSaveSuccess = saveImage(False,index,img_url,nickName,postNumber)\n",
    "                    #np arr from img_url for validation\n",
    "                    PredictionWithoutDownload(img_url)\n",
    "    #                 if(isSaveSuccess):  \n",
    "    #                     index = index+1\n",
    "    #         print(\"---{}s seconds---\".format(time.time()-start_time),\".2f\")\n",
    "    except Exception as ex:\n",
    "        print(\"error catch : \" , ex)\n",
    "        print(\"url : \" ,img_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title : 기가 막혔던 종각 맛집 , href : https://forurwinter.blog.me/221988900945\n",
      "----------------------------------\n",
      "title : 푸짐했던 종각 맛집 , href : https://blog.naver.com/celinicious?Redirect=Log&logNo=222006262433\n",
      "----------------------------------\n",
      "title : 여기가 핫플! 종각 맛집 , href : https://blog.naver.com/limmmm22?Redirect=Log&logNo=222012963389\n",
      "----------------------------------\n",
      "title : 종각 맛집 매콤한 파스타 , href : https://blog.naver.com/kangmj1992?Redirect=Log&logNo=222011821916\n",
      "----------------------------------\n",
      "title : 가성비 쩔었던 종각 맛집, 교대이층집 , href : https://blog.naver.com/el512?Redirect=Log&logNo=222008681533\n",
      "----------------------------------\n",
      "title : 0324 종각 고기집/콜키지프리 맛집 고메식당 , href : https://blog.naver.com/p_radn?Redirect=Log&logNo=221878088433\n",
      "----------------------------------\n",
      "title : 믿고갔던 종각 맛집 , href : https://blog.naver.com/porky0122?Redirect=Log&logNo=221991050525\n",
      "----------------------------------\n",
      "title : 끝장난 종각 맛집 , href : https://ssomerry.blog.me/221983614903\n",
      "----------------------------------\n",
      "title : 까리했던 종각 맛집 , href : https://blog.naver.com/ju_love1202?Redirect=Log&logNo=221952793333\n",
      "----------------------------------\n",
      "title : 흐뭇했던 종각 맛집 , href : https://blog.naver.com/hoon1033?Redirect=Log&logNo=221995568472\n",
      "----------------------------------\n",
      "------ digging more -------\n",
      "nickName :  forurwinter\n",
      "postNumber :  221988900945\n",
      "blogUrl :  https://m.blog.naver.com/forurwinter?Redirect=Log&logNo=221988900945\n",
      "---[1] 0.17281198501586914s seconds---\n",
      "---[2] 0.0002276897430419922s seconds---\n",
      "---[3] 0.012222051620483398s seconds---\n",
      "---[4] 0.0007927417755126953s seconds---\n",
      "---[5] 0.049810171127319336s seconds---\n",
      "========pridiction[Without Download]========\n",
      "predictions class :  [[1]]\n",
      "---[1] 0.1127779483795166s seconds---\n",
      "---[2] 0.00011491775512695312s seconds---\n",
      "---[3] 0.01240396499633789s seconds---\n",
      "---[4] 0.0007088184356689453s seconds---\n",
      "---[5] 0.046447038650512695s seconds---\n",
      "========pridiction[Without Download]========\n",
      "predictions class :  [[1]]\n",
      "---[1] 0.263369083404541s seconds---\n",
      "---[2] 0.0001220703125s seconds---\n",
      "---[3] 0.0148773193359375s seconds---\n",
      "---[4] 0.0008308887481689453s seconds---\n",
      "---[5] 0.042601823806762695s seconds---\n",
      "========pridiction[Without Download]========\n",
      "predictions class :  [[1]]\n",
      "---[1] 0.04620075225830078s seconds---\n",
      "---[2] 0.00011587142944335938s seconds---\n",
      "---[3] 0.01358485221862793s seconds---\n",
      "---[4] 0.0005881786346435547s seconds---\n",
      "---[5] 0.04249095916748047s seconds---\n",
      "========pridiction[Without Download]========\n",
      "predictions class :  [[1]]\n",
      "---[1] 0.058776140213012695s seconds---\n",
      "---[2] 0.00011086463928222656s seconds---\n",
      "---[3] 0.01182103157043457s seconds---\n",
      "---[4] 0.0005638599395751953s seconds---\n",
      "---[5] 0.040695905685424805s seconds---\n",
      "========pridiction[Without Download]========\n",
      "predictions class :  [[1]]\n",
      "---[1] 0.052622079849243164s seconds---\n",
      "---[2] 0.00013494491577148438s seconds---\n",
      "---[3] 0.013246297836303711s seconds---\n",
      "---[4] 0.0009150505065917969s seconds---\n",
      "---[5] 0.04357504844665527s seconds---\n",
      "========pridiction[Without Download]========\n",
      "predictions class :  [[1]]\n",
      "---[1] 0.05779099464416504s seconds---\n",
      "---[2] 0.00015687942504882812s seconds---\n",
      "---[3] 0.012812137603759766s seconds---\n",
      "---[4] 0.0005850791931152344s seconds---\n",
      "---[5] 0.041159868240356445s seconds---\n",
      "========pridiction[Without Download]========\n",
      "predictions class :  [[1]]\n",
      "---[1] 0.0559840202331543s seconds---\n",
      "---[2] 0.0001709461212158203s seconds---\n",
      "---[3] 0.014039993286132812s seconds---\n",
      "---[4] 0.0006830692291259766s seconds---\n",
      "---[5] 0.04028916358947754s seconds---\n",
      "========pridiction[Without Download]========\n",
      "predictions class :  [[1]]\n",
      "---[1] 0.04788398742675781s seconds---\n",
      "---[2] 0.00010704994201660156s seconds---\n",
      "---[3] 0.01232290267944336s seconds---\n",
      "---[4] 0.0008530616760253906s seconds---\n",
      "---[5] 0.05220293998718262s seconds---\n",
      "========pridiction[Without Download]========\n",
      "predictions class :  [[1]]\n",
      "---[1] 0.050556182861328125s seconds---\n",
      "---[2] 0.00011086463928222656s seconds---\n",
      "---[3] 0.012818098068237305s seconds---\n",
      "---[4] 0.001026153564453125s seconds---\n",
      "---[5] 0.04609799385070801s seconds---\n",
      "========pridiction[Without Download]========\n",
      "predictions class :  [[1]]\n",
      "---[1] 0.05129599571228027s seconds---\n",
      "---[2] 9.989738464355469e-05s seconds---\n",
      "---[3] 0.013243913650512695s seconds---\n",
      "---[4] 0.0006430149078369141s seconds---\n",
      "---[5] 0.04282522201538086s seconds---\n",
      "========pridiction[Without Download]========\n",
      "predictions class :  [[1]]\n",
      "---[1] 0.05432295799255371s seconds---\n",
      "---[2] 0.00013184547424316406s seconds---\n",
      "---[3] 0.013440608978271484s seconds---\n",
      "---[4] 0.0007212162017822266s seconds---\n",
      "---[5] 0.04123973846435547s seconds---\n",
      "========pridiction[Without Download]========\n",
      "predictions class :  [[1]]\n",
      "---[1] 0.04445981979370117s seconds---\n",
      "---[2] 0.0001087188720703125s seconds---\n",
      "---[3] 0.011925935745239258s seconds---\n",
      "---[4] 0.0005948543548583984s seconds---\n",
      "---[5] 0.03966784477233887s seconds---\n",
      "========pridiction[Without Download]========\n",
      "predictions class :  [[1]]\n",
      "---[1] 0.05793309211730957s seconds---\n",
      "---[2] 0.00013589859008789062s seconds---\n",
      "---[3] 0.013673782348632812s seconds---\n",
      "---[4] 0.000614166259765625s seconds---\n",
      "---[5] 0.04208183288574219s seconds---\n",
      "========pridiction[Without Download]========\n",
      "predictions class :  [[1]]\n",
      "---[1] 0.047388315200805664s seconds---\n",
      "---[2] 0.00010991096496582031s seconds---\n",
      "---[3] 0.012763738632202148s seconds---\n",
      "---[4] 0.0006847381591796875s seconds---\n",
      "---[5] 0.040962934494018555s seconds---\n",
      "========pridiction[Without Download]========\n",
      "predictions class :  [[1]]\n",
      "---[1] 0.04773712158203125s seconds---\n",
      "---[2] 0.00013494491577148438s seconds---\n",
      "---[3] 0.013125896453857422s seconds---\n",
      "---[4] 0.0006508827209472656s seconds---\n",
      "---[5] 0.04190206527709961s seconds---\n",
      "========pridiction[Without Download]========\n",
      "predictions class :  [[1]]\n",
      "---[1] 0.048464059829711914s seconds---\n",
      "---[2] 0.00010395050048828125s seconds---\n",
      "---[3] 0.011204957962036133s seconds---\n",
      "---[4] 0.0005991458892822266s seconds---\n",
      "---[5] 0.044618844985961914s seconds---\n",
      "========pridiction[Without Download]========\n",
      "predictions class :  [[1]]\n",
      "---[1] 0.05217909812927246s seconds---\n",
      "---[2] 0.00010013580322265625s seconds---\n",
      "---[3] 0.011427879333496094s seconds---\n",
      "---[4] 0.0007171630859375s seconds---\n",
      "---[5] 0.040019989013671875s seconds---\n",
      "========pridiction[Without Download]========\n",
      "predictions class :  [[1]]\n",
      "---[1] 0.047942161560058594s seconds---\n",
      "---[2] 0.00010967254638671875s seconds---\n",
      "---[3] 0.012158870697021484s seconds---\n",
      "---[4] 0.0006809234619140625s seconds---\n",
      "---[5] 0.051957130432128906s seconds---\n",
      "========pridiction[Without Download]========\n",
      "predictions class :  [[1]]\n",
      "---[1] 0.044936180114746094s seconds---\n",
      "---[2] 0.00011396408081054688s seconds---\n",
      "---[3] 0.012379169464111328s seconds---\n",
      "---[4] 0.0010788440704345703s seconds---\n",
      "---[5] 0.03985285758972168s seconds---\n",
      "========pridiction[Without Download]========\n",
      "predictions class :  [[1]]\n",
      "---[1] 0.04669690132141113s seconds---\n",
      "---[2] 0.0001087188720703125s seconds---\n",
      "---[3] 0.012564897537231445s seconds---\n",
      "---[4] 0.0005960464477539062s seconds---\n",
      "---[5] 0.04347681999206543s seconds---\n",
      "========pridiction[Without Download]========\n",
      "predictions class :  [[1]]\n",
      "---[1] 0.04242300987243652s seconds---\n",
      "---[2] 0.00010395050048828125s seconds---\n",
      "---[3] 0.011434078216552734s seconds---\n",
      "---[4] 0.0006210803985595703s seconds---\n",
      "---[5] 0.04153132438659668s seconds---\n",
      "========pridiction[Without Download]========\n",
      "predictions class :  [[1]]\n",
      "---[1] 0.053601741790771484s seconds---\n",
      "---[2] 0.00011014938354492188s seconds---\n",
      "---[3] 0.012768030166625977s seconds---\n",
      "---[4] 0.0006346702575683594s seconds---\n",
      "---[5] 0.04297900199890137s seconds---\n",
      "========pridiction[Without Download]========\n",
      "predictions class :  [[1]]\n",
      "---[1] 0.048728227615356445s seconds---\n",
      "---[2] 0.00010704994201660156s seconds---\n",
      "---[3] 0.012604951858520508s seconds---\n",
      "---[4] 0.0005896091461181641s seconds---\n",
      "---[5] 0.041628122329711914s seconds---\n",
      "========pridiction[Without Download]========\n",
      "predictions class :  [[1]]\n",
      "---[1] 0.04999399185180664s seconds---\n",
      "---[2] 0.00010919570922851562s seconds---\n",
      "---[3] 0.012422323226928711s seconds---\n",
      "---[4] 0.0006241798400878906s seconds---\n",
      "---[5] 0.03866910934448242s seconds---\n",
      "========pridiction[Without Download]========\n",
      "predictions class :  [[1]]\n",
      "---[1] 0.043168067932128906s seconds---\n",
      "---[2] 0.0001010894775390625s seconds---\n",
      "---[3] 0.010533809661865234s seconds---\n",
      "---[4] 0.0006020069122314453s seconds---\n",
      "---[5] 0.041925907135009766s seconds---\n",
      "========pridiction[Without Download]========\n",
      "predictions class :  [[1]]\n",
      "---[1] 0.048131704330444336s seconds---\n",
      "---[2] 0.00010180473327636719s seconds---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---[3] 0.012233972549438477s seconds---\n",
      "---[4] 0.0005908012390136719s seconds---\n",
      "---[5] 0.04234123229980469s seconds---\n",
      "========pridiction[Without Download]========\n",
      "predictions class :  [[1]]\n",
      "---[1] 0.05333304405212402s seconds---\n",
      "---[2] 0.00013208389282226562s seconds---\n",
      "---[3] 0.013607978820800781s seconds---\n",
      "---[4] 0.0006549358367919922s seconds---\n",
      "---[5] 0.05255722999572754s seconds---\n",
      "========pridiction[Without Download]========\n",
      "predictions class :  [[1]]\n",
      "---[1] 0.04969501495361328s seconds---\n",
      "---[2] 0.00010991096496582031s seconds---\n",
      "---[3] 0.013007164001464844s seconds---\n",
      "---[4] 0.0012850761413574219s seconds---\n",
      "---[5] 0.04936504364013672s seconds---\n",
      "========pridiction[Without Download]========\n",
      "predictions class :  [[1]]\n",
      "---[1] 0.049405813217163086s seconds---\n",
      "---[2] 0.00010704994201660156s seconds---\n",
      "---[3] 0.01200413703918457s seconds---\n",
      "---[4] 0.00066375732421875s seconds---\n",
      "---[5] 0.04227566719055176s seconds---\n",
      "========pridiction[Without Download]========\n",
      "predictions class :  [[1]]\n",
      "------ digging more -------\n",
      "nickName :  celinicious\n",
      "postNumber :  222006262433\n",
      "blogUrl :  https://m.blog.naver.com/celinicious?Redirect=Log&logNo=222006262433\n",
      "---[1] 0.03632783889770508s seconds---\n",
      "---[2] 9.393692016601562e-05s seconds---\n",
      "---[3] 0.001413106918334961s seconds---\n",
      "---[4] 0.0006771087646484375s seconds---\n",
      "---[5] 0.040284156799316406s seconds---\n",
      "========pridiction[Without Download]========\n",
      "predictions class :  [[0]]\n",
      "error catch :  'ascii' codec can't encode characters in position 150-153: ordinal not in range(128)\n",
      "url :  https://mblogthumb-phinf.pstatic.net/MjAyMDA2MTlfNzkg/MDAxNTkyNTY1MjI2ODQz.QU1FfOXMQ06x5sL5WYVWbiWo6HPZGl0IABQ3frFlOOQg.tdK7rKO0XerpZ9fIdHtEA4Svph32oV4LMf0i-4_BJDUg.JPEG.celinicious/종각맛집_쟁반집8292_1.jpg?type=w800\n"
     ]
    }
   ],
   "source": [
    "searchQuery = \"종각 맛집\"\n",
    "searchOption = 'sim'  #sim or date  \n",
    "page = 1\n",
    "\n",
    "findBlogImgGethering(searchQuery,searchOption,page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
